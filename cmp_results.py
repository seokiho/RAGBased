import json
import re
from typing import Dict, List, Tuple
from collections import Counter
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from difflib import SequenceMatcher

class LegalQAComparator:
    """ë²•ë¥  QA ì‹œìŠ¤í…œì˜ ë‹µë³€ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, generated_file: str, parsed_file: str):
        """
        Args:
            generated_file: generated_questions.json íŒŒì¼ ê²½ë¡œ
            parsed_file: parsed_results.json íŒŒì¼ ê²½ë¡œ
        """
        with open(generated_file, 'r', encoding='utf-8') as f:
            self.generated_data = json.load(f)
        
        with open(parsed_file, 'r', encoding='utf-8') as f:
            self.parsed_data = json.load(f)
        
        # query_id ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­
        self.parsed_dict = {item['query_id']: item for item in self.parsed_data}
        
        self.results = []
    
    def normalize_law_name(self, law: str) -> str:
        """ë²•ë ¹ëª… ì •ê·œí™”"""
        # ã€Œã€ ì œê±°
        law = law.replace('ã€Œ', '').replace('ã€', '')
        # ê³µë°± ì œê±°
        law = law.replace(' ', '')
        # ì˜ë¬¸ì ì†Œë¬¸ì ë³€í™˜
        law = law.lower()
        return law
    
    def extract_law_references(self, text: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ ì°¸ì¡°ë¥¼ ì¶”ì¶œí•˜ê³  ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        # ë‹¤ì–‘í•œ ë²•ë ¹ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            r'ã€Œ([^ã€]+)ã€\s*ì œ(\d+)ì¡°(?:ì˜(\d+))?(?:\s*ì œ(\d+)í•­)?',
            r'([ê°€-í£]+ë²•)\s*ì œ(\d+)ì¡°(?:ì˜(\d+))?(?:\s*ì œ(\d+)í•­)?',
        ]
        
        laws = []
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                law_info = {
                    'full': match.group(0),
                    'law_name': match.group(1),
                    'article': match.group(2),
                    'sub_article': match.group(3) if len(match.groups()) > 2 else None,
                    'paragraph': match.group(4) if len(match.groups()) > 3 else None,
                }
                laws.append(law_info)
        
        return laws
    
    def calculate_text_similarity(self, text1: str, text2: str) -> Dict[str, float]:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ê³„ì‚°"""
        
        # 1. TF-IDF ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        vectorizer = TfidfVectorizer()
        try:
            tfidf_matrix = vectorizer.fit_transform([text1, text2])
            cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        except:
            cosine_sim = 0.0
        
        # 2. ë¬¸ì ìˆ˜ì¤€ ìœ ì‚¬ë„
        seq_sim = SequenceMatcher(None, text1, text2).ratio()
        
        # 3. ë‹¨ì–´ ì§‘í•© ê¸°ë°˜ Jaccard ìœ ì‚¬ë„
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if len(words1.union(words2)) > 0:
            jaccard_sim = len(words1.intersection(words2)) / len(words1.union(words2))
        else:
            jaccard_sim = 0.0
        
        return {
            'tfidf_cosine': round(cosine_sim, 4),
            'sequence_matcher': round(seq_sim, 4),
            'jaccard': round(jaccard_sim, 4),
            'average': round((cosine_sim + seq_sim + jaccard_sim) / 3, 4)
        }
    
    def compare_law_references(self, gen_laws: str, parsed_laws: str) -> Dict:
        """ë²•ë ¹ ì°¸ì¡°ì˜ ì¼ì¹˜ë„ ë¹„êµ - ê°œì„ ëœ ë²„ì „"""
        laws1 = self.extract_law_references(gen_laws)
        laws2 = self.extract_law_references(parsed_laws)
        
        # ë²•ë ¹ëª…ë§Œ ì¶”ì¶œ (ì •ê·œí™”)
        law_names1 = set([self.normalize_law_name(l['law_name']) for l in laws1])
        law_names2 = set([self.normalize_law_name(l['law_name']) for l in laws2])
        
        # ë²•ë ¹ëª… + ì¡°í•­ (ì •ê·œí™”)
        law_articles1 = set([
            f"{self.normalize_law_name(l['law_name'])}ì œ{l['article']}ì¡°" 
            for l in laws1
        ])
        law_articles2 = set([
            f"{self.normalize_law_name(l['law_name'])}ì œ{l['article']}ì¡°" 
            for l in laws2
        ])
        
        # ë§¤ì¹­ ê³„ì‚°
        law_name_match = law_names1.intersection(law_names2)
        article_match = law_articles1.intersection(law_articles2)
        
        # Precision, Recall ê³„ì‚°
        precision_name = len(law_name_match) / len(law_names1) if law_names1 else 0
        recall_name = len(law_name_match) / len(law_names2) if law_names2 else 0
        
        precision_article = len(article_match) / len(law_articles1) if law_articles1 else 0
        recall_article = len(article_match) / len(law_articles2) if law_articles2 else 0
        
        return {
            'generated_laws': [l['full'] for l in laws1],
            'parsed_laws': [l['full'] for l in laws2],
            'generated_law_names': list(law_names1),
            'parsed_law_names': list(law_names2),
            'law_name_matches': list(law_name_match),
            'article_matches': list(article_match),
            'metrics': {
                'law_name_precision': round(precision_name, 4),
                'law_name_recall': round(recall_name, 4),
                'article_precision': round(precision_article, 4),
                'article_recall': round(recall_article, 4)
            }
        }
    
    def extract_case_numbers(self, text: str) -> List[str]:
        """íŒë¡€ ë²ˆí˜¸ ì¶”ì¶œ"""
        pattern = r'\d{4}[ê°€-í£]+\d+'
        return list(set(re.findall(pattern, text)))
    
    def compare_cases(self, gen_data: Dict, parsed_data: Dict) -> Dict:
        """íŒë¡€ ì°¸ì¡° ë¹„êµ"""
        gen_case_num = gen_data.get('ì‚¬ê±´ë²ˆí˜¸', '')
        gen_case_ref = gen_data.get('ì°¸ì¡°íŒë¡€', '')
        parsed_case_ref = parsed_data.get('relevant_cases', '')
        
        # ì‚¬ê±´ë²ˆí˜¸ê°€ parsed_dataì˜ ë‹µë³€ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        case_number_mentioned = gen_case_num in parsed_case_ref if gen_case_num else False
        
        # parsed_dataì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ
        parsed_case_numbers = self.extract_case_numbers(parsed_case_ref)
        
        # íŒë¡€ ë‚´ìš©ì˜ ìœ ì‚¬ë„
        similarity = self.calculate_text_similarity(gen_case_ref, parsed_case_ref)
        
        return {
            'reference_case_number': gen_case_num,
            'parsed_case_numbers': parsed_case_numbers,
            'case_number_mentioned': case_number_mentioned,
            'has_case_reference': len(parsed_case_ref) > 10,  # íŒë¡€ ì„¤ëª…ì´ ìˆëŠ”ì§€
            'case_similarity': similarity
        }
    
    def calculate_f1_score(self, precision: float, recall: float) -> float:
        """F1 Score ê³„ì‚°"""
        if precision + recall > 0:
            return 2 * (precision * recall) / (precision + recall)
        return 0.0
    
    def compare_single_pair(self, gen_item: Dict, parsed_item: Dict) -> Dict:
        """ê°œë³„ ì§ˆë¬¸-ë‹µë³€ ìŒ ë¹„êµ"""
        
        # 1. ì§ˆë¬¸ ì¼ì¹˜ í™•ì¸
        gen_question = gen_item.get('ì§ˆë¬¸', '').replace('ì§ˆë¬¸: ', '')
        parsed_question = parsed_item.get('query', '')
        question_match = gen_question.strip() == parsed_question.strip()
        
        # 2. ë‹µë³€ ë‚´ìš© ìœ ì‚¬ë„
        gen_answer = gen_item.get('ë‹µë³€', '')
        parsed_answer = parsed_item.get('answer_content', '')
        answer_similarity = self.calculate_text_similarity(gen_answer, parsed_answer)
        
        # 3. ë²•ë ¹ ë¹„êµ
        gen_laws = gen_item.get('ì°¸ì¡°ì¡°ë¬¸', '') + '\n' + gen_answer
        parsed_laws = parsed_item.get('relevant_laws', '') + '\n' + parsed_answer
        law_comparison = self.compare_law_references(gen_laws, parsed_laws)
        
        # 4. íŒë¡€ ë¹„êµ
        case_comparison = self.compare_cases(gen_item, parsed_item)
        
        # 5. ì¢…í•© ë©”íŠ¸ë¦­
        law_metrics = law_comparison['metrics']
        f1_law_name = self.calculate_f1_score(
            law_metrics['law_name_precision'], 
            law_metrics['law_name_recall']
        )
        f1_article = self.calculate_f1_score(
            law_metrics['article_precision'], 
            law_metrics['article_recall']
        )
        
        return {
            'question': gen_question[:100] + '...' if len(gen_question) > 100 else gen_question,
            'question_match': question_match,
            'answer_similarity': answer_similarity,
            'law_comparison': law_comparison,
            'case_comparison': case_comparison,
            'summary_metrics': {
                'answer_similarity_avg': answer_similarity['average'],
                'law_name_f1': round(f1_law_name, 4),
                'article_f1': round(f1_article, 4),
                'has_case_reference': case_comparison['has_case_reference']
            }
        }
    
    def compare_all(self) -> List[Dict]:
        """ëª¨ë“  ì§ˆë¬¸-ë‹µë³€ ìŒ ë¹„êµ"""
        for idx, gen_item in enumerate(self.generated_data, 1):
            query_id = str(idx)
            
            if query_id in self.parsed_dict:
                parsed_item = self.parsed_dict[query_id]
                comparison = self.compare_single_pair(gen_item, parsed_item)
                comparison['query_id'] = query_id
                self.results.append(comparison)
            else:
                print(f"Warning: query_id {query_id}ê°€ parsed_resultsì— ì—†ìŠµë‹ˆë‹¤.")
        
        return self.results
    
    def generate_summary_statistics(self) -> Dict:
        """ì „ì²´ í†µê³„ ìš”ì•½"""
        if not self.results:
            return {}
        
        # ë‹µë³€ ìœ ì‚¬ë„ í‰ê· 
        avg_answer_sim = {
            'tfidf_cosine': np.mean([r['answer_similarity']['tfidf_cosine'] for r in self.results]),
            'sequence_matcher': np.mean([r['answer_similarity']['sequence_matcher'] for r in self.results]),
            'jaccard': np.mean([r['answer_similarity']['jaccard'] for r in self.results]),
            'average': np.mean([r['answer_similarity']['average'] for r in self.results])
        }
        
        # ë²•ë ¹ ë§¤ì¹­ í†µê³„
        law_name_f1_scores = [r['summary_metrics']['law_name_f1'] for r in self.results]
        article_f1_scores = [r['summary_metrics']['article_f1'] for r in self.results]
        
        # íŒë¡€ ì°¸ì¡° í†µê³„
        has_case_count = sum([r['summary_metrics']['has_case_reference'] for r in self.results])
        case_number_match_count = sum([r['case_comparison']['case_number_mentioned'] for r in self.results])
        
        # ë²•ë ¹ëª…ì´ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨
        law_name_match_rate = np.mean([
            1 if len(r['law_comparison']['law_name_matches']) > 0 else 0 
            for r in self.results
        ])
        
        return {
            'total_comparisons': len(self.results),
            'answer_similarity': {
                'tfidf_cosine': round(avg_answer_sim['tfidf_cosine'], 4),
                'sequence_matcher': round(avg_answer_sim['sequence_matcher'], 4),
                'jaccard': round(avg_answer_sim['jaccard'], 4),
                'average': round(avg_answer_sim['average'], 4)
            },
            'law_matching': {
                'avg_law_name_f1': round(np.mean(law_name_f1_scores), 4),
                'avg_article_f1': round(np.mean(article_f1_scores), 4),
                'law_name_match_rate': round(law_name_match_rate, 4),
                'perfect_match_count': sum([1 for score in law_name_f1_scores if score == 1.0])
            },
            'case_reference': {
                'has_case_reference_rate': round(has_case_count / len(self.results), 4),
                'case_number_match_count': case_number_match_count,
                'case_number_match_rate': round(case_number_match_count / len(self.results), 4)
            }
        }
    
    def save_results(self, output_file: str = 'comparison_results.json'):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        summary = self.generate_summary_statistics()
        
        output = {
            'summary_statistics': summary,
            'detailed_results': self.results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def print_summary(self):
        """ìš”ì•½ í†µê³„ ì¶œë ¥"""
        summary = self.generate_summary_statistics()
        
        print("\n" + "=" * 70)
        print("ğŸ“Š ë²•ë¥  QA ë‹µë³€ ë¹„êµ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)
        
        print(f"\nğŸ“‹ ì´ ë¹„êµ ê±´ìˆ˜: {summary['total_comparisons']}")
        
        print("\nğŸ“ [ë‹µë³€ ìœ ì‚¬ë„]")
        print(f"  â€¢ TF-IDF ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {summary['answer_similarity']['tfidf_cosine']:.1%}")
        print(f"  â€¢ Sequence Matcher: {summary['answer_similarity']['sequence_matcher']:.1%}")
        print(f"  â€¢ Jaccard ìœ ì‚¬ë„: {summary['answer_similarity']['jaccard']:.1%}")
        print(f"  â€¢ í‰ê·  ìœ ì‚¬ë„: {summary['answer_similarity']['average']:.1%}")
        
        print("\nâš–ï¸  [ë²•ë ¹ ì°¸ì¡° ì •í™•ë„]")
        print(f"  â€¢ ë²•ë ¹ëª… ì¼ì¹˜ìœ¨: {summary['law_matching']['law_name_match_rate']:.1%}")
        print(f"  â€¢ ë²•ë ¹ëª… F1 Score: {summary['law_matching']['avg_law_name_f1']:.1%}")
        print(f"  â€¢ ì¡°í•­ F1 Score: {summary['law_matching']['avg_article_f1']:.1%}")
        print(f"  â€¢ ì™„ë²½ ë§¤ì¹­ ê±´ìˆ˜: {summary['law_matching']['perfect_match_count']}ê±´")
        
        print(f"\nğŸ“– [íŒë¡€ ì°¸ì¡°]")
        print(f"  â€¢ íŒë¡€ ì„¤ëª… í¬í•¨ë¥ : {summary['case_reference']['has_case_reference_rate']:.1%}")
        print(f"  â€¢ ì‚¬ê±´ë²ˆí˜¸ ì¼ì¹˜ ê±´ìˆ˜: {summary['case_reference']['case_number_match_count']}ê±´")
        print(f"  â€¢ ì‚¬ê±´ë²ˆí˜¸ ì¼ì¹˜ìœ¨: {summary['case_reference']['case_number_match_rate']:.1%}")
        
        print("\n" + "=" * 70)
    
    def print_detailed_examples(self, n: int = 3):
        """ìƒì„¸ ë¹„êµ ì˜ˆì‹œ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print(f"ğŸ” ìƒì„¸ ë¹„êµ ì˜ˆì‹œ (ì²˜ìŒ {n}ê°œ)")
        print("=" * 70)
        
        for i, result in enumerate(self.results[:n], 1):
            print(f"\n[ì˜ˆì‹œ {i}] Query ID: {result['query_id']}")
            print(f"ì§ˆë¬¸: {result['question']}")
            print(f"\në‹µë³€ ìœ ì‚¬ë„: {result['answer_similarity']['average']:.1%}")
            
            print(f"\nì°¸ì¡° ë²•ë ¹ ë¹„êµ:")
            print(f"  Generated: {result['law_comparison']['generated_law_names']}")
            print(f"  Parsed: {result['law_comparison']['parsed_law_names']}")
            print(f"  ì¼ì¹˜: {result['law_comparison']['law_name_matches']}")
            
            print(f"\níŒë¡€ ì •ë³´:")
            print(f"  ì°¸ì¡° ì‚¬ê±´ë²ˆí˜¸: {result['case_comparison']['reference_case_number']}")
            print(f"  Parsed ì‚¬ê±´ë²ˆí˜¸: {result['case_comparison']['parsed_case_numbers']}")
            print(f"  íŒë¡€ ì„¤ëª… í¬í•¨: {result['case_comparison']['has_case_reference']}")
            print("-" * 70)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸš€ ë²•ë¥  QA ë‹µë³€ ë¹„êµ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    # ë¹„êµ ìˆ˜í–‰
    comparator = LegalQAComparator(
        './DATA/generated_questions.json',
        'parsed_results.json'
    )
    
    # ë¹„êµ ì‹¤í–‰
    results = comparator.compare_all()
    
    # ìš”ì•½ í†µê³„ ì¶œë ¥
    comparator.print_summary()
    
    # ìƒì„¸ ì˜ˆì‹œ ì¶œë ¥
    comparator.print_detailed_examples(n=3)
    
    # ê²°ê³¼ ì €ì¥
    comparator.save_results('comparison_results.json')